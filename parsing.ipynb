{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Storing Highest-Grossing Films Data\n",
    "\n",
    "### This script extracts information about the highest-grossing films from Wikipedia, processes the data, and saves it in both a SQLite database and a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "\n",
    "response = requests.get(URL)\n",
    "if response.status_code != 200:\n",
    "    print(\"request error\", response.status_code)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Approach\n",
    "\n",
    "### 1. **Fetching the Wikipedia Page**\n",
    "I use `requests.get(URL)` to send an HTTP request and check for a successful response (`status_code == 200`).\n",
    "\n",
    "### 2. **Extracting the Main Table**\n",
    "I use `BeautifulSoup`for locating the table and extracting all rows of the first table.\n",
    "\n",
    "### 3. **Extracting Film Details**\n",
    "For each row I extract the **title** and the link to the film's page and then visit the film's Wikipedia page and extract information below by searching for specific table headers (`th`) and extracting text from their corresponding `td` elements:\n",
    "  - **Release Year** (`bday` class)\n",
    "  - **Director(s)** (under the \"Directed by\" table row)\n",
    "  - **Box Office Earnings** (under the \"Box office\" table row)\n",
    "  - **Country** (under the \"Country\" table row)\n",
    "\n",
    "### 4. **Handling Errors & Delays**\n",
    "- **Error Handling:** I use `try-except` to safe script from stop.\n",
    "- **Delays:** I didn't use delay before and it overwhelmed Wikipedia servers and I was blocked, so now I use`time.sleep(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсим Avatar -> https://en.wikipedia.org/wiki/Avatar_(2009_film)\n",
      "Парсим Avengers: Endgame -> https://en.wikipedia.org/wiki/Avengers:_Endgame\n",
      "Парсим Avatar: The Way of Water -> https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water\n",
      "Парсим Titanic -> https://en.wikipedia.org/wiki/Titanic_(1997_film)\n",
      "Парсим Star Wars: The Force Awakens -> https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens\n",
      "Парсим Avengers: Infinity War -> https://en.wikipedia.org/wiki/Avengers:_Infinity_War\n",
      "Парсим Ne Zha 2 -> https://en.wikipedia.org/wiki/Ne_Zha_2\n",
      "Парсим Spider-Man: No Way Home -> https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home\n",
      "Парсим Inside Out 2 -> https://en.wikipedia.org/wiki/Inside_Out_2\n",
      "Парсим Jurassic World -> https://en.wikipedia.org/wiki/Jurassic_World\n",
      "Парсим The Lion King -> https://en.wikipedia.org/wiki/The_Lion_King_(2019_film)\n",
      "Парсим The Avengers -> https://en.wikipedia.org/wiki/The_Avengers_(2012_film)\n",
      "Парсим Furious 7 -> https://en.wikipedia.org/wiki/Furious_7\n",
      "Парсим Top Gun: Maverick -> https://en.wikipedia.org/wiki/Top_Gun:_Maverick\n",
      "Парсим Frozen 2 -> https://en.wikipedia.org/wiki/Frozen_2\n",
      "Парсим Barbie -> https://en.wikipedia.org/wiki/Barbie_(film)\n",
      "Парсим Avengers: Age of Ultron -> https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron\n",
      "Парсим The Super Mario Bros. Movie -> https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie\n",
      "Парсим Black Panther -> https://en.wikipedia.org/wiki/Black_Panther_(film)\n",
      "Парсим Harry Potter and the Deathly Hallows – Part 2 -> https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2\n",
      "Парсим Deadpool & Wolverine -> https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine\n",
      "Парсим Star Wars: The Last Jedi -> https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi\n",
      "Парсим Jurassic World: Fallen Kingdom -> https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom\n",
      "Парсим Frozen -> https://en.wikipedia.org/wiki/Frozen_(2013_film)\n",
      "Парсим Beauty and the Beast -> https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)\n",
      "Парсим Incredibles 2 -> https://en.wikipedia.org/wiki/Incredibles_2\n",
      "Парсим The Fate of the Furious -> https://en.wikipedia.org/wiki/The_Fate_of_the_Furious\n",
      "Парсим Iron Man 3 -> https://en.wikipedia.org/wiki/Iron_Man_3\n",
      "Парсим Minions -> https://en.wikipedia.org/wiki/Minions_(film)\n",
      "Парсим Captain America: Civil War -> https://en.wikipedia.org/wiki/Captain_America:_Civil_War\n",
      "Парсим Aquaman -> https://en.wikipedia.org/wiki/Aquaman_(film)\n",
      "Парсим The Lord of the Rings: The Return of the King -> https://en.wikipedia.org/wiki/The_Lord_of_the_Rings:_The_Return_of_the_King\n",
      "Парсим Spider-Man: Far From Home -> https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home\n",
      "Парсим Captain Marvel -> https://en.wikipedia.org/wiki/Captain_Marvel_(film)\n",
      "Парсим Transformers: Dark of the Moon -> https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon\n",
      "Парсим Skyfall -> https://en.wikipedia.org/wiki/Skyfall\n",
      "Парсим Transformers: Age of Extinction -> https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction\n",
      "Парсим The Dark Knight Rises -> https://en.wikipedia.org/wiki/The_Dark_Knight_Rises\n",
      "Парсим Joker -> https://en.wikipedia.org/wiki/Joker_(2019_film)\n",
      "Парсим Star Wars: The Rise of Skywalker -> https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker\n",
      "Парсим Toy Story 4 -> https://en.wikipedia.org/wiki/Toy_Story_4\n",
      "Парсим Toy Story 3 -> https://en.wikipedia.org/wiki/Toy_Story_3\n",
      "Парсим Pirates of the Caribbean: Dead Man's Chest -> https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest\n",
      "Парсим Rogue One: A Star Wars Story -> https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story\n",
      "Парсим Moana 2 -> https://en.wikipedia.org/wiki/Moana_2\n",
      "Парсим Aladdin -> https://en.wikipedia.org/wiki/Aladdin_(2019_film)\n",
      "Парсим Star Wars: Episode I – The Phantom Menace -> https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace\n",
      "Парсим Pirates of the Caribbean: On Stranger Tides -> https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides\n",
      "Парсим Jurassic Park -> https://en.wikipedia.org/wiki/Jurassic_Park_(film)\n",
      "Парсим Despicable Me 3 -> https://en.wikipedia.org/wiki/Despicable_Me_3\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "films_table = soup.find(\"table\", class_=\"wikitable\")\n",
    "if not films_table:\n",
    "    exit()\n",
    "\n",
    "rows = films_table.find_all(\"tr\")[1:] \n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) < 5:\n",
    "        continue\n",
    "\n",
    "    title_tag = row.find(\"th\", scope=\"row\").find(\"a\") if row.find(\"th\", scope=\"row\") else None\n",
    "    if not title_tag:\n",
    "        continue\n",
    "\n",
    "    title = title_tag.get_text(strip=True)\n",
    "    film_url = \"https://en.wikipedia.org\" + title_tag[\"href\"]\n",
    "    \n",
    "    print(f\"Парсим {title} -> {film_url}\")\n",
    "\n",
    "    try:\n",
    "        film_response = requests.get(film_url)\n",
    "        film_soup = BeautifulSoup(film_response.text, \"html.parser\")\n",
    "        \n",
    "\n",
    "        year_tag = film_soup.find(\"span\", class_=\"bday\")\n",
    "        release_year = year_tag.get_text(strip=True)[:4] if year_tag else \"0000\"\n",
    "\n",
    "        director_tag = film_soup.find(\"th\", string=\"Directed by\")\n",
    "        director = \"Unknown\"\n",
    "        if director_tag:\n",
    "            director_data = director_tag.find_next_sibling(\"td\")\n",
    "            if director_data:\n",
    "                director = \", \".join([a.get_text(strip=True) for a in director_data.find_all(\"a\")]) or director_data.get_text(strip=True)\n",
    "\n",
    "        box_office_tag = film_soup.find(\"th\", string=\"Box office\")\n",
    "        box_office = \"Unknown\"\n",
    "        if box_office_tag:\n",
    "            box_office_data = box_office_tag.find_next_sibling(\"td\")\n",
    "            box_office = box_office_data.get_text(strip=True) if box_office_data else \"Unknown\"\n",
    "\n",
    "        country_tag = film_soup.find(\"th\", string=\"Country\")\n",
    "        country = \"Unknown\"\n",
    "        if country_tag:\n",
    "            country_data = country_tag.find_next_sibling(\"td\")\n",
    "            if country_data:\n",
    "                country = \", \".join([a.get_text(strip=True) for a in country_data.find_all(\"a\")]) or country_data.get_text(strip=True)\n",
    "\n",
    "\n",
    "        data.append((title, int(release_year), director, box_office, country))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error {title}: {e}\")\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for empty data\n",
    "Few times I faced problem with empty json, so added this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning \n",
    "**I didn't need to clean anything, except Box Office Data.**\n",
    "\n",
    "Wikipedia often contains footnotes (`[1]`, `[2]`), empty boxes, and inconsistent formatting.\n",
    "The function `clean_box_office()` removes these artifacts using:\n",
    "  - `re.sub(r\"\\[.*?\\]\", \"\", value)` to remove footnotes.\n",
    "  - `re.sub(r\"(\\d)(?=[mbMB])\", r\"\\1 \", value)` for proper spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_box_office(value):\n",
    "    if value == \"Unknown\":\n",
    "        return value\n",
    "    value = re.sub(r\"\\[.*?\\]\", \"\", value)  \n",
    "    value = re.sub(r\"(\\d)(?=[mbMB])\", r\"\\1 \", value)  \n",
    "    return value.strip()\n",
    "\n",
    "data = [(title, release_year, director, clean_box_office(box_office), country) for title, release_year, director, box_office, country in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data in SQLite Database\n",
    "### 1. **Creating the Database & Table**\n",
    "\n",
    "I use SQLite (`sqlite3`) to create a `films.db` database with a table and then `executemany()` to insert all rows:\n",
    "  - `title` (TEXT, NOT NULL)\n",
    "  - `release_year` (INEGER)\n",
    "  - `director` (TEXT)\n",
    "  - `box_office` (TEXT)\n",
    "  - `country` (TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"films.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS films (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    release_year TEXT,\n",
    "    director TEXT,\n",
    "    box_office TEXT,\n",
    "    country TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.executemany(\"INSERT INTO films (title, release_year, director, box_office, country) VALUES (?, ?, ?, ?, ?)\", data)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data to JSON\n",
    "\n",
    "I used `json.dump()` with `ensure_ascii=False` to preserve non-ASCII characters in case there are non-English film titles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"films.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump([{\"title\": d[0], \"release_year\": d[1], \"director\": d[2], \"box_office\": d[3], \"country\": d[4]} for d in data], f, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
